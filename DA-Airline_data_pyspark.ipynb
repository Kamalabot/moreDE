{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e841b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa7f0ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d41eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is another way to extract the files from multiple types of compressed files.\n",
    "#https://docs.python.org/3/library/shutil.html\n",
    "import shutil\n",
    "#shutil.unpack_archive('airLineCapitalOne.zip','newdata')\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('airLineCapitalOne.zip','r') as ref:\n",
    "    ref.extractall('airLineData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f133e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "metaData = pd.read_excel(\"airLineData/Airline_Challenge_Metadata.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddbd65a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightsPath = \"airLineData/Flights.csv\"\n",
    "ticketsPath = \"airLineData/Tickets.csv\"\n",
    "AirPortCodesPath = \"airLineData/Airport_Codes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "872c214a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/23 20:11:28 WARN Utils: Your hostname, codeStation resolves to a loopback address: 127.0.1.1; using 172.17.0.1 instead (on interface docker0)\n",
      "22/11/23 20:11:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/23 20:11:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#Starting the pyspark session\n",
    "spark = SparkSession.builder.appName(\"CapitalOne DA\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed74a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the local database for storing the data\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS capitalone_DA\")\n",
    "spark.sql(\"USE capitalone_DA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60508f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Reading the files \n",
    "flights= spark.read.csv(flightsPath,inferSchema=True,header=True)\n",
    "tickets= spark.read.csv(ticketsPath, inferSchema=True, header=True)\n",
    "airport= spark.read.csv(AirPortCodesPath, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96be7ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The tables can be read directly like below using read.parquet\n",
    "airport = spark.read.parquet(\"spark-warehouse/capitalone_da.db/airport/\")\n",
    "tickets = spark.read.parquet(\"spark-warehouse/capitalone_da.db/tickets/\")\n",
    "flights = spark.read.parquet(\"spark-warehouse/capitalone_da.db/flights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12dac942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating views in the database\n",
    "flights.createOrReplaceTempView(\"flights\")\n",
    "tickets.createOrReplaceTempView(\"tickets\")\n",
    "airport.createOrReplaceTempView(\"airport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be9887e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Savings tables to the database as permanents\n",
    "flights.write.saveAsTable('flights')\n",
    "airport.write.saveAsTable('airport')\n",
    "tickets.write.saveAsTable('tickets')\n",
    "#The second time the above commands are not required as the tables will be there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36ea0853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+-----------------+-----------------+------+----------------+---------------+-----------+-----------------+---------+---------+---------+--------+--------+--------------+\n",
      "|   FL_DATE|OP_CARRIER|TAIL_NUM|OP_CARRIER_FL_NUM|ORIGIN_AIRPORT_ID|ORIGIN|ORIGIN_CITY_NAME|DEST_AIRPORT_ID|DESTINATION|   DEST_CITY_NAME|DEP_DELAY|ARR_DELAY|CANCELLED|AIR_TIME|DISTANCE|OCCUPANCY_RATE|\n",
      "+----------+----------+--------+-----------------+-----------------+------+----------------+---------------+-----------+-----------------+---------+---------+---------+--------+--------+--------------+\n",
      "|2019-03-31|        UA|  N839UA|             1485|            13930|   ORD|     Chicago, IL|          11066|        CMH|     Columbus, OH|     -2.0|      2.0|      0.0|    46.0|   296.0|          0.46|\n",
      "|2019-03-31|        UA|  N590UA|             1483|            11618|   EWR|      Newark, NJ|          14771|        SFO|San Francisco, CA|     -4.0|    -11.0|      0.0|   338.0|  2565.0|          0.64|\n",
      "+----------+----------+--------+-----------------+-----------------+------+----------------+---------------+-----------+-----------------+---------+---------+---------+--------+--------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e2c1894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+-----------+\n",
      "|namespace|      tableName|isTemporary|\n",
      "+---------+---------------+-----------+\n",
      "|         |        airport|       true|\n",
      "|         |flightcondensed|       true|\n",
      "|         |        flights|       true|\n",
      "|         |        tickets|       true|\n",
      "+---------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Temporary tables of the above data is created in the spark execution environment\n",
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fa5fae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- TAIL_NUM: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: string (nullable = true)\n",
      " |-- ORIGIN_AIRPORT_ID: integer (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- ORIGIN_CITY_NAME: string (nullable = true)\n",
      " |-- DEST_AIRPORT_ID: integer (nullable = true)\n",
      " |-- DESTINATION: string (nullable = true)\n",
      " |-- DEST_CITY_NAME: string (nullable = true)\n",
      " |-- DEP_DELAY: double (nullable = true)\n",
      " |-- ARR_DELAY: double (nullable = true)\n",
      " |-- CANCELLED: double (nullable = true)\n",
      " |-- AIR_TIME: string (nullable = true)\n",
      " |-- DISTANCE: string (nullable = true)\n",
      " |-- OCCUPANCY_RATE: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flights.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f225071c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TYPE: string (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- ELEVATION_FT: double (nullable = true)\n",
      " |-- CONTINENT: string (nullable = true)\n",
      " |-- ISO_COUNTRY: string (nullable = true)\n",
      " |-- MUNICIPALITY: string (nullable = true)\n",
      " |-- IATA_CODE: string (nullable = true)\n",
      " |-- COORDINATES: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2b0b7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ITIN_ID: long (nullable = true)\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- QUARTER: integer (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY: string (nullable = true)\n",
      " |-- ORIGIN_STATE_ABR: string (nullable = true)\n",
      " |-- ORIGIN_STATE_NM: string (nullable = true)\n",
      " |-- ROUNDTRIP: double (nullable = true)\n",
      " |-- REPORTING_CARRIER: string (nullable = true)\n",
      " |-- PASSENGERS: double (nullable = true)\n",
      " |-- ITIN_FARE: string (nullable = true)\n",
      " |-- DESTINATION: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tickets.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f501a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The df.sql function APIs are helpful \n",
    "flights_condensed = flights.select(date_format(col('FL_DATE'),'y-MM-dd').alias('flight_date'),\n",
    "                'OP_CARRIER','TAIL_NUM','OP_CARRIER_FL_NUM','ORIGIN','DESTINATION',\n",
    "               'DEP_DELAY','ARR_DELAY','CANCELLED','AIR_TIME','DISTANCE',\n",
    "               'OCCUPANCY_RATE')\n",
    "flights_condensed.createOrReplaceTempView(\"flightCondensed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22d746ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------+-----------------+------+-----------+---------+---------+---------+--------+--------+--------------+\n",
      "|flight_date|OP_CARRIER|TAIL_NUM|OP_CARRIER_FL_NUM|ORIGIN|DESTINATION|DEP_DELAY|ARR_DELAY|CANCELLED|AIR_TIME|DISTANCE|OCCUPANCY_RATE|\n",
      "+-----------+----------+--------+-----------------+------+-----------+---------+---------+---------+--------+--------+--------------+\n",
      "| 2019-03-02|        WN|  N955WN|             4591|   RSW|        CLE|     -8.0|     -6.0|      0.0|   143.0|  1025.0|          0.97|\n",
      "| 2019-03-02|        WN|  N8686A|             3231|   RSW|        CMH|      1.0|      5.0|      0.0|   135.0|   930.0|          0.55|\n",
      "| 2019-03-02|        WN|  N201LV|             3383|   RSW|        CMH|      0.0|      4.0|      0.0|   132.0|   930.0|          0.91|\n",
      "| 2019-03-02|        WN|  N413WN|             5498|   RSW|        CMH|     11.0|     14.0|      0.0|   136.0|   930.0|          0.67|\n",
      "| 2019-03-02|        WN|  N7832A|             6933|   RSW|        DAL|      0.0|    -17.0|      0.0|   151.0|  1005.0|          0.62|\n",
      "+-----------+----------+--------+-----------------+------+-----------+---------+---------+---------+--------+--------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM flightCondensed LIMIT 5\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "698ac362",
   "metadata": {},
   "outputs": [],
   "source": [
    "airportCondensed = spark.sql(\"\"\"SELECT TYPE, NAME, ELEVATION_FT, MUNICIPALITY, IATA_CODE, COORDINATES FROM airport\"\"\")\n",
    "airportCondensed.createOrReplaceTempView(\"airportCondensed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76d252f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+------------+------------+---------+--------------------+\n",
      "|         TYPE|                NAME|ELEVATION_FT|MUNICIPALITY|IATA_CODE|         COORDINATES|\n",
      "+-------------+--------------------+------------+------------+---------+--------------------+\n",
      "|     heliport|   Total Rf Heliport|        11.0|    Bensalem|     null|-74.9336013793945...|\n",
      "|small_airport|Aero B Ranch Airport|      3435.0|       Leoti|     null|-101.473911, 38.7...|\n",
      "|small_airport|        Lowell Field|       450.0|Anchor Point|     null|-151.695999146, 5...|\n",
      "|small_airport|        Epps Airpark|       820.0|     Harvest|     null|-86.7703018188476...|\n",
      "|       closed|Newport Hospital ...|       237.0|     Newport|     null| -91.254898, 35.6087|\n",
      "+-------------+--------------------+------------+------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM airportCondensed\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c940da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticketsCondensed = spark.sql(\"\"\"SELECT ITIN_ID, YEAR, QUARTER, ORIGIN, ORIGIN_STATE_ABR, DESTINATION,\n",
    "              ROUNDTRIP, REPORTING_CARRIER, PASSENGERS, ITIN_FARE FROM tickets\"\"\")\n",
    "ticketsCondensed.createOrReplaceTempView(\"ticketsCondensed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a3c53",
   "metadata": {},
   "source": [
    "Analytics questions on the Airline data\n",
    "0) On each date, how many flights are there\n",
    "1) How many unique flights are there in the datasets\n",
    "2) Which flights have travelled the longest distance\n",
    "3) Which routes has the maximum flights\n",
    "4) Which routes has the maximum number of round trips\n",
    "5) What is the highest elevation of the airport\n",
    "6) Which route has the maximum revenue\n",
    "7) Which route has the maximum number of passenger\n",
    "8) What is the number of passenger carried by the aircraft till date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2c89526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|flight_date|flight_counts|\n",
      "+-----------+-------------+\n",
      "| 2019-03-15|        23361|\n",
      "| 2019-03-14|        23305|\n",
      "| 2019-03-22|        23258|\n",
      "| 2019-03-29|        23250|\n",
      "| 2019-03-11|        23249|\n",
      "+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#What is the number of flights operating on each date\n",
    "\n",
    "spark.sql(\"\"\"SELECT flight_date, COUNT(flight_date) AS flight_counts \n",
    "            FROM flightCondensed\n",
    "            GROUP BY flight_date\n",
    "            ORDER BY COUNT(flight_date) DESC\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbf54e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|TAIL_NUM|tripCounts|\n",
      "+--------+----------+\n",
      "|  N485HA|       928|\n",
      "|  N479HA|       882|\n",
      "|  N483HA|       882|\n",
      "|  N480HA|       875|\n",
      "|  N491HA|       873|\n",
      "+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many unique flights are there in the datasets\n",
    "spark.sql(\"\"\"SELECT TAIL_NUM, \n",
    "                COUNT(TAIL_NUM) AS tripCounts\n",
    "                FROM flightCondensed\n",
    "                GROUP BY TAIL_NUM\n",
    "                ORDER BY COUNT(TAIL_NUM) DESC\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d80a74b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|OP_CARRIER|tripCounts|\n",
      "+----------+----------+\n",
      "|        WN|    326093|\n",
      "|        AA|    232403|\n",
      "|        DL|    225391|\n",
      "|        OO|    194934|\n",
      "|        UA|    142826|\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many trips each operator has done\n",
    "spark.sql(\"\"\"SELECT OP_CARRIER,\n",
    "                COUNT(TAIL_NUM) AS tripCounts\n",
    "                FROM flightCondensed\n",
    "                GROUP BY OP_CARRIER\n",
    "                ORDER BY COUNT(TAIL_NUM) DESC\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5f120b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many different carriers are there in the datasets?\n",
    "spark.sql(\"\"\"SELECT OP_CARRIER,\n",
    "                COUNT(TAIL_NUM) AS tripCounts\n",
    "                FROM flightCondensed\n",
    "                GROUP BY OP_CARRIER\n",
    "                ORDER BY COUNT(TAIL_NUM) DESC\"\"\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8386c758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|TAIL_NUM|\n",
      "+--------+\n",
      "|  N8554X|\n",
      "|  N8322X|\n",
      "|  N954WN|\n",
      "|  N8513F|\n",
      "|  N445WN|\n",
      "|  N8525S|\n",
      "|  N914WN|\n",
      "|  N8511K|\n",
      "|  N251WN|\n",
      "|  N496WN|\n",
      "|  N8734Q|\n",
      "|  N448WN|\n",
      "|  N240WN|\n",
      "|  N430WN|\n",
      "|  N8634A|\n",
      "|  N757LV|\n",
      "|  N7838A|\n",
      "|  N7715E|\n",
      "|  N8679A|\n",
      "|  N404WN|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many flight numbers are there under each flight numbers\n",
    "spark.sql(\"\"\"SELECT DISTINCT TAIL_NUM\n",
    "              FROM flightCondensed\n",
    "              WHERE OP_CARRIER = 'WN'\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e24c987f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|TAIL_NUM|\n",
      "+--------+\n",
      "|  N8554X|\n",
      "|  N8322X|\n",
      "|  N954WN|\n",
      "|  N8513F|\n",
      "|  N445WN|\n",
      "|  N8525S|\n",
      "|  N914WN|\n",
      "|  N8511K|\n",
      "|  N251WN|\n",
      "|  N496WN|\n",
      "|  N8734Q|\n",
      "|  N448WN|\n",
      "|  N240WN|\n",
      "|  N430WN|\n",
      "|  N8634A|\n",
      "|  N757LV|\n",
      "|  N7838A|\n",
      "|  N7715E|\n",
      "|  N8679A|\n",
      "|  N404WN|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many flight numbers are there under each flight numbers\n",
    "spark.sql(\"\"\"SELECT DISTINCT TAIL_NUM\n",
    "              FROM flightCondensed\n",
    "              WHERE OP_CARRIER = 'WN'\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bbfca566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 62:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|TOTAL_DELAY|TAIL_NUM|\n",
      "+-----------+--------+\n",
      "|    19178.0|  N927SW|\n",
      "|    16269.0|  N786SK|\n",
      "|    15404.0|  N14143|\n",
      "|    15099.0|  N920SW|\n",
      "|    15015.0|  N21197|\n",
      "|    14694.0|  N908EV|\n",
      "|    14103.0|  N11191|\n",
      "|    14051.0|  N954SW|\n",
      "|    13938.0|  N780SK|\n",
      "|    13888.0|  N758EV|\n",
      "|    13885.0|  N690CA|\n",
      "|    13843.0|  N693BR|\n",
      "|    13755.0|  N880AS|\n",
      "|    13672.0|  N466SW|\n",
      "|    13518.0|  N788SK|\n",
      "|    13352.0|  N134SY|\n",
      "|    13292.0|  N760SK|\n",
      "|    13198.0|  N871AS|\n",
      "|    13173.0|  N331CA|\n",
      "|    13172.0|  N791SK|\n",
      "+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Which flight numbers are getting delayed frequently\n",
    "spark.sql(\"\"\"SELECT SUM(DEP_DELAY) AS TOTAL_DELAY, TAIL_NUM\n",
    "            FROM flightCondensed\n",
    "            GROUP BY TAIL_NUM\n",
    "            ORDER BY SUM(DEP_DELAY) DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ca7f58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|TOTAL_DELAY|OP_CARRIER|\n",
      "+-----------+----------+\n",
      "|  3179490.0|        WN|\n",
      "|  3014699.0|        OO|\n",
      "|  2251096.0|        AA|\n",
      "|  1785352.0|        DL|\n",
      "|  1708696.0|        UA|\n",
      "|  1308290.0|        B6|\n",
      "|   686371.0|        MQ|\n",
      "|   623717.0|        9E|\n",
      "|   603639.0|        YX|\n",
      "|   590527.0|        OH|\n",
      "|   569127.0|        YV|\n",
      "|   520857.0|        EV|\n",
      "|   401598.0|        G7|\n",
      "|   389617.0|        NK|\n",
      "|   361070.0|        F9|\n",
      "|   350897.0|        AX|\n",
      "|   348663.0|        AS|\n",
      "|   335448.0|        C5|\n",
      "|   326916.0|        CP|\n",
      "|   243367.0|        ZW|\n",
      "+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#What is the total departure delays of the Op_carriers\n",
    "spark.sql(\"\"\"SELECT SUM(DEP_DELAY) AS TOTAL_DELAY, OP_CARRIER\n",
    "            FROM flightCondensed\n",
    "            GROUP BY OP_CARRIER\n",
    "            ORDER BY SUM(DEP_DELAY) DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c57fde30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|TOTAL_DELAY|TAIL_NUM|\n",
      "+-----------+--------+\n",
      "|    17831.0|  N927SW|\n",
      "|    15995.0|  N786SK|\n",
      "|    14752.0|  N14143|\n",
      "|    14664.0|  N21197|\n",
      "|    14096.0|  N920SW|\n",
      "|    13809.0|  N908EV|\n",
      "|    13369.0|  N780SK|\n",
      "|    13311.0|  N788SK|\n",
      "|    13231.0|  N11191|\n",
      "|    13060.0|  N693BR|\n",
      "|    12944.0|  N954SW|\n",
      "|    12920.0|  N880AS|\n",
      "|    12713.0|  N758EV|\n",
      "|    12712.0|  N760SK|\n",
      "|    12607.0|  N134SY|\n",
      "|    12543.0|  N466SW|\n",
      "|    12371.0|  N18120|\n",
      "|    12348.0|  N791SK|\n",
      "|    12254.0|  N782SK|\n",
      "|    12130.0|  N14204|\n",
      "+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Which flight numbers are getting delayed frequently\n",
    "spark.sql(\"\"\"SELECT SUM(ARR_DELAY) AS TOTAL_DELAY, TAIL_NUM\n",
    "            FROM flightCondensed\n",
    "            GROUP BY TAIL_NUM\n",
    "            ORDER BY SUM(ARR_DELAY) DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ebea516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|TOTAL_DELAY|OP_CARRIER|\n",
      "+-----------+----------+\n",
      "|  2173234.0|        OO|\n",
      "|  1228558.0|        AA|\n",
      "|  1017167.0|        UA|\n",
      "|   893889.0|        B6|\n",
      "|   750513.0|        WN|\n",
      "|   559109.0|        MQ|\n",
      "|   457229.0|        EV|\n",
      "|   454123.0|        YV|\n",
      "|   354137.0|        YX|\n",
      "|   313872.0|        C5|\n",
      "|   311863.0|        AX|\n",
      "|   275975.0|        G7|\n",
      "|   254221.0|        OH|\n",
      "|   242416.0|        CP|\n",
      "|   205151.0|        AS|\n",
      "|   191928.0|        9E|\n",
      "|   177492.0|        F9|\n",
      "|   175002.0|        QX|\n",
      "|   157844.0|        ZW|\n",
      "|   147277.0|        G4|\n",
      "+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#What is the total departure delays of the Op_carriers\n",
    "spark.sql(\"\"\"SELECT SUM(ARR_DELAY) AS TOTAL_DELAY, OP_CARRIER\n",
    "            FROM flightCondensed\n",
    "            GROUP BY OP_CARRIER\n",
    "            ORDER BY SUM(ARR_DELAY) DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f646b399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(flight_date='2019-03-22', DEP_TOTAL_DELAY=258541.0, ARR_TOTAL_DELAY=133729.0),\n",
       " Row(flight_date='2019-03-23', DEP_TOTAL_DELAY=116769.0, ARR_TOTAL_DELAY=-34271.0),\n",
       " Row(flight_date='2019-03-24', DEP_TOTAL_DELAY=144381.0, ARR_TOTAL_DELAY=-27920.0),\n",
       " Row(flight_date='2019-03-25', DEP_TOTAL_DELAY=183577.0, ARR_TOTAL_DELAY=47952.0),\n",
       " Row(flight_date='2019-03-26', DEP_TOTAL_DELAY=75968.0, ARR_TOTAL_DELAY=-76875.0),\n",
       " Row(flight_date='2019-03-27', DEP_TOTAL_DELAY=117087.0, ARR_TOTAL_DELAY=-39843.0),\n",
       " Row(flight_date='2019-03-28', DEP_TOTAL_DELAY=95720.0, ARR_TOTAL_DELAY=-69509.0),\n",
       " Row(flight_date='2019-03-29', DEP_TOTAL_DELAY=103217.0, ARR_TOTAL_DELAY=-57336.0),\n",
       " Row(flight_date='2019-03-30', DEP_TOTAL_DELAY=69542.0, ARR_TOTAL_DELAY=-74062.0),\n",
       " Row(flight_date='2019-03-31', DEP_TOTAL_DELAY=135289.0, ARR_TOTAL_DELAY=-3327.0)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How is the departure and arrival delays on each date?\n",
    "spark.sql(\"\"\"SELECT flight_date, SUM(DEP_DELAY) AS DEP_TOTAL_DELAY,\n",
    "                    SUM(ARR_DELAY) AS ARR_TOTAL_DELAY\n",
    "                    FROM flightCondensed\n",
    "                    GROUP BY flight_date\n",
    "                    ORDER BY flight_date\"\"\").tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a82ca4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(flight_date=None, DEP_TOTAL_DELAY=30560.0, ARR_TOTAL_DELAY=3950.0),\n",
       " Row(flight_date='2019-01-01', DEP_TOTAL_DELAY=232562.0, ARR_TOTAL_DELAY=128217.0),\n",
       " Row(flight_date='2019-01-02', DEP_TOTAL_DELAY=291099.0, ARR_TOTAL_DELAY=193013.0),\n",
       " Row(flight_date='2019-01-03', DEP_TOTAL_DELAY=193078.0, ARR_TOTAL_DELAY=56174.0),\n",
       " Row(flight_date='2019-01-04', DEP_TOTAL_DELAY=110566.0, ARR_TOTAL_DELAY=-52259.0),\n",
       " Row(flight_date='2019-01-05', DEP_TOTAL_DELAY=159352.0, ARR_TOTAL_DELAY=30358.0),\n",
       " Row(flight_date='2019-01-06', DEP_TOTAL_DELAY=259492.0, ARR_TOTAL_DELAY=120118.0),\n",
       " Row(flight_date='2019-01-07', DEP_TOTAL_DELAY=135680.0, ARR_TOTAL_DELAY=-5475.0),\n",
       " Row(flight_date='2019-01-08', DEP_TOTAL_DELAY=65511.0, ARR_TOTAL_DELAY=-82616.0),\n",
       " Row(flight_date='2019-01-09', DEP_TOTAL_DELAY=45445.0, ARR_TOTAL_DELAY=-92416.0)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT flight_date, SUM(DEP_DELAY) AS DEP_TOTAL_DELAY,\n",
    "                    SUM(ARR_DELAY) AS ARR_TOTAL_DELAY\n",
    "                    FROM flightCondensed\n",
    "                    GROUP BY flight_date\n",
    "                    ORDER BY flight_date\"\"\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "34c4ef99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 108:>                                                        (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+\n",
      "|flight_date|OP_CARRIER|DEP_DELAY|TAIL_NUM|\n",
      "+-----------+----------+---------+--------+\n",
      "| 2019-01-08|        AA|   1281.0|  N905NN|\n",
      "| 2019-01-08|        OO|   1014.0|  N805SK|\n",
      "| 2019-01-08|        OO|   1010.0|  N805SK|\n",
      "| 2019-01-08|        AA|    837.0|  N315RJ|\n",
      "| 2019-01-08|        G7|    833.0|  N153GJ|\n",
      "| 2019-01-08|        AX|    829.0|  N11155|\n",
      "| 2019-01-08|        EV|    683.0|  N14905|\n",
      "| 2019-01-08|        DL|    655.0|  N955AT|\n",
      "| 2019-01-08|        9E|    654.0|  N176PQ|\n",
      "| 2019-01-08|        OO|    631.0|  N703SK|\n",
      "| 2019-01-08|        C5|    629.0|  N16183|\n",
      "| 2019-01-08|        AA|    611.0|  N967AN|\n",
      "| 2019-01-08|        G7|    599.0|  N369CA|\n",
      "| 2019-01-08|        OO|    531.0|  N603SK|\n",
      "| 2019-01-08|        OO|    506.0|  N873AS|\n",
      "| 2019-01-08|        C5|    492.0|  N27190|\n",
      "| 2019-01-08|        YV|    443.0|  N507MJ|\n",
      "| 2019-01-08|        OO|    438.0|  N906SW|\n",
      "| 2019-01-08|        C5|    425.0|  N12195|\n",
      "| 2019-01-08|        UA|    412.0|  N36444|\n",
      "+-----------+----------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 108:==============>                                          (1 + 3) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#On each date, what is the delay of each op_carrier\n",
    "spark.sql(\"\"\"SELECT flight_date, OP_CARRIER,DEP_DELAY,TAIL_NUM\n",
    "                FROM flightCondensed\n",
    "                WHERE flight_date = '2019-01-08'\n",
    "                ORDER BY DEP_DELAY DESC\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4314bde2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a860aa7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f024d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2cb2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0f249b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c66c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623883d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4735205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a7a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b272cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4501aa58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
