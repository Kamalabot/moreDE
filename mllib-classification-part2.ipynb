{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kamaljp/mllib-classification-part2?scriptVersionId=112195079\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","id":"1fd0274a","metadata":{"papermill":{"duration":0.008831,"end_time":"2022-11-27T07:11:01.696627","exception":false,"start_time":"2022-11-27T07:11:01.687796","status":"completed"},"tags":[]},"source":["### Clustering, Classification and Regression\n","\n","The notebook brings together all the algorithms used for classification and regression challenges. The features has been selected in the [MLLib part1](MLlib_training_part1) notebook. The logical next step is covering the fitting and prediction using the models"]},{"cell_type":"code","execution_count":1,"id":"85b4e364","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:11:01.713864Z","iopub.status.busy":"2022-11-27T07:11:01.713063Z","iopub.status.idle":"2022-11-27T07:11:53.628196Z","shell.execute_reply":"2022-11-27T07:11:53.627158Z"},"papermill":{"duration":51.92689,"end_time":"2022-11-27T07:11:53.631076","exception":false,"start_time":"2022-11-27T07:11:01.704186","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyspark\r\n","  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n","\u001b[?25hCollecting py4j==0.10.9.5\r\n","  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hBuilding wheels for collected packages: pyspark\r\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n","\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845513 sha256=ca7f7a7828869e77d0c49d753ba80f399dbc71c4311004783e954424c1271413\r\n","  Stored in directory: /root/.cache/pip/wheels/42/59/f5/79a5bf931714dcd201b26025347785f087370a10a3329a899c\r\n","Successfully built pyspark\r\n","Installing collected packages: py4j, pyspark\r\n","  Attempting uninstall: py4j\r\n","    Found existing installation: py4j 0.10.9.7\r\n","    Uninstalling py4j-0.10.9.7:\r\n","      Successfully uninstalled py4j-0.10.9.7\r\n","Successfully installed py4j-0.10.9.5 pyspark-3.3.1\r\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n","\u001b[0m"]}],"source":["!pip install pyspark"]},{"cell_type":"code","execution_count":2,"id":"bb693c78","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:11:53.677789Z","iopub.status.busy":"2022-11-27T07:11:53.677154Z","iopub.status.idle":"2022-11-27T07:11:53.740687Z","shell.execute_reply":"2022-11-27T07:11:53.7394Z"},"papermill":{"duration":0.089184,"end_time":"2022-11-27T07:11:53.743329","exception":false,"start_time":"2022-11-27T07:11:53.654145","status":"completed"},"tags":[]},"outputs":[],"source":["import pyspark\n","from pyspark.sql import SparkSession "]},{"cell_type":"code","execution_count":3,"id":"297a5956","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:11:53.786911Z","iopub.status.busy":"2022-11-27T07:11:53.786492Z","iopub.status.idle":"2022-11-27T07:11:59.697309Z","shell.execute_reply":"2022-11-27T07:11:59.695933Z"},"papermill":{"duration":5.937342,"end_time":"2022-11-27T07:11:59.701852","exception":false,"start_time":"2022-11-27T07:11:53.76451","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"]},{"name":"stdout","output_type":"stream","text":["22/11/27 07:11:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]}],"source":["#Initiating Pyspark\n","spark = SparkSession.builder.appName(\"CCRModels\").getOrCreate()"]},{"cell_type":"code","execution_count":4,"id":"e040ec52","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:11:59.751433Z","iopub.status.busy":"2022-11-27T07:11:59.751026Z","iopub.status.idle":"2022-11-27T07:11:59.915425Z","shell.execute_reply":"2022-11-27T07:11:59.91389Z"},"papermill":{"duration":0.190409,"end_time":"2022-11-27T07:11:59.91826","exception":false,"start_time":"2022-11-27T07:11:59.727851","status":"completed"},"tags":[]},"outputs":[],"source":["#The classification algorithms are under the ml.classification\n","from pyspark.ml import Pipeline\n","from pyspark.ml.classification import DecisionTreeClassifier, LogisticRegression\n","from pyspark.ml.classification import RandomForestClassifier,GBTClassifier\n","from pyspark.ml.classification import MultilayerPerceptronClassifier,LinearSVC,OneVsRest\n","from pyspark.ml.classification import NaiveBayes, FMClassifier\n","from pyspark.ml.feature import StringIndexer, VectorIndexer,IndexToString,MinMaxScaler\n","from pyspark.ml.evaluation import MulticlassClassificationEvaluator"]},{"cell_type":"code","execution_count":5,"id":"4be23bd0","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:11:59.962955Z","iopub.status.busy":"2022-11-27T07:11:59.96251Z","iopub.status.idle":"2022-11-27T07:11:59.968576Z","shell.execute_reply":"2022-11-27T07:11:59.967661Z"},"papermill":{"duration":0.030665,"end_time":"2022-11-27T07:11:59.97083","exception":false,"start_time":"2022-11-27T07:11:59.940165","status":"completed"},"tags":[]},"outputs":[],"source":["#The regression algorithms are under the ml.regression \n","from pyspark.ml.regression import DecisionTreeRegressor, LinearRegression\n","from pyspark.ml.regression import RandomForestRegressor,GBTRegressor\n","from pyspark.ml.regression import FMRegressor"]},{"cell_type":"code","execution_count":6,"id":"657a3031","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:12:00.014603Z","iopub.status.busy":"2022-11-27T07:12:00.014137Z","iopub.status.idle":"2022-11-27T07:12:07.052342Z","shell.execute_reply":"2022-11-27T07:12:07.050164Z"},"papermill":{"duration":7.065986,"end_time":"2022-11-27T07:12:07.057873","exception":false,"start_time":"2022-11-27T07:11:59.991887","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["22/11/27 07:12:01 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+-----+--------------------+\n","|label|            features|\n","+-----+--------------------+\n","|  0.0|(692,[127,128,129...|\n","|  1.0|(692,[158,159,160...|\n","|  1.0|(692,[124,125,126...|\n","|  1.0|(692,[152,153,154...|\n","|  1.0|(692,[151,152,153...|\n","+-----+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["# Load and parse the data file, converting it to a DataFrame.\n","data = spark.read.format(\"libsvm\").load(\"/kaggle/input/mllib-datasets/sample_libsvm_data.txt\")\n","data.show(5)"]},{"cell_type":"markdown","id":"39c759a2","metadata":{"papermill":{"duration":0.032435,"end_time":"2022-11-27T07:12:07.123797","exception":false,"start_time":"2022-11-27T07:12:07.091362","status":"completed"},"tags":[]},"source":["### FM Classifier"]},{"cell_type":"code","execution_count":7,"id":"1cef28e7","metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2022-11-27T07:12:07.193544Z","iopub.status.busy":"2022-11-27T07:12:07.192959Z","iopub.status.idle":"2022-11-27T07:12:22.963221Z","shell.execute_reply":"2022-11-27T07:12:22.962022Z"},"jupyter":{"outputs_hidden":true},"papermill":{"duration":15.808408,"end_time":"2022-11-27T07:12:22.966692","exception":false,"start_time":"2022-11-27T07:12:07.158284","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------+------------+--------------------+\n","|prediction|indexedLabel|            features|\n","+----------+------------+--------------------+\n","|       1.0|         1.0|(692,[98,99,100,1...|\n","|       1.0|         1.0|(692,[100,101,102...|\n","|       1.0|         1.0|(692,[122,123,124...|\n","|       1.0|         1.0|(692,[123,124,125...|\n","|       1.0|         1.0|(692,[123,124,125...|\n","+----------+------------+--------------------+\n","only showing top 5 rows\n","\n","Test set accuracy = 1\n","Factors: DenseMatrix([[-0.0110321 , -0.01691307,  0.01537207, ..., -0.00414937,\n","              -0.00739385,  0.02161043],\n","             [ 0.00713033,  0.00184908,  0.02839882, ..., -0.01141896,\n","              -0.00457819, -0.00872833],\n","             [ 0.01270881, -0.00951992,  0.01556508, ...,  0.00393716,\n","               0.01803246,  0.00827956],\n","             ...,\n","             [ 0.02924058, -0.03169198,  0.00525453, ..., -0.03144299,\n","               0.01266851, -0.01506852],\n","             [ 0.04002274, -0.03244643,  0.02994511, ..., -0.02156527,\n","               0.02087353, -0.02271996],\n","             [ 0.00759856, -0.0070223 ,  0.02783338, ..., -0.03023709,\n","               0.01843239, -0.03891505]])\n","Linear: [-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.017028298014013312,0.017028298014013312,-0.0070492798243505725,-0.030039219192181135,-0.029769439064080836,-0.02945239690968681,-0.025775612955041282,-0.02378764017369258,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031534297088395724,-0.03153429708839572,-0.03440538506292793,0.01355002399257361,-0.0274526459507117,-0.0332943658701305,-0.03378082923251862,-0.03355479144840894,-0.02078033787050726,-0.019942306157942815,-0.03214360771835507,-0.03106791499286682,-0.031078548832438928,-0.0328872344249004,0.012807344111473624,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031534297088395724,-0.031534297088395724,-0.033988874479398905,-0.0265423762650682,0.0057478317160352755,0.0028888869534297815,-0.03367761823771692,-0.03307531484819299,-0.01875748949939146,-0.015371064650050595,-0.019387419664022534,-0.034039253697223236,-0.029519201174519772,-0.034074361149061705,-0.025357692994644812,0.010012306805832009,0.015985177738155696,0.0,0.0,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031534297088395724,-0.03823445232827598,-0.005302070281556231,0.007260123970230689,0.009886394589493985,-0.0002578306511871653,-0.015984408935716305,-0.01919423185323243,-0.021030911261798187,-0.018589513450817677,-0.02444709525460964,-0.028726856565831134,-0.025198539145095743,-0.024860394114405958,0.00506372086299519,0.0076593905447191685,0.009935800135573197,0.0,0.0,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.015386285891658958,0.005126938293653537,0.009516600507964218,0.008889526720778302,0.007270731861650081,0.004313206339554934,-0.005974911891871553,-0.013467960787570442,-0.02670355199689706,-0.0262929255884102,-0.028401626171577453,-0.02063035306681757,-0.0184647341719787,-0.006334854009562426,0.008732881342645172,0.005979721550361943,-0.00045625218387916773,0.012807045048378585,0.0,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.01747364258764852,0.017220577795669507,0.01631700984425363,0.01035122177579825,0.005019678258259167,0.00981890891755879,0.009063099984402726,-0.0046694504787425165,-0.02339486059579325,-0.03455726380365796,-0.03213174303040995,-0.03204298867503617,-0.026580688850482148,-0.01638276826010993,0.00762425245422173,0.012896805950824692,0.012610995678533658,0.009594383446310795,0.015157266972440554,0.016321505328388563,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.01634462395017331,0.017213217180648464,0.01621006809088778,0.012360847624255772,0.010998446157473942,0.011476843301389341,0.012166265229712198,-0.007214798734502552,-0.026482544150707235,-0.029895990520739005,-0.027736696393346482,-0.027419759012281174,-0.030542500407298293,-0.02371830576502387,0.013914438365624981,0.01722712407706294,0.017583627821861816,0.016920734070326474,0.01459527740556925,0.016272815074863722,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.017599840183385132,0.0169398988989498,0.015887466501205875,0.014997358147200164,0.013741188841036379,0.01197845650317135,0.008312565287477104,-0.0056396689249439275,-0.03266344446953216,-0.02805218747618874,-0.026417728864877987,-0.02578356890609713,-0.02881172259532835,-0.025124747628406687,0.012584576134581514,0.01710129137730467,0.018375083041323067,0.01963432632522627,0.02205133184513181,0.017744526100926198,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.016880555936246083,0.018161148534056756,0.016567532112533336,0.013761601346844045,0.01270660038088488,0.009014988677467231,0.01047771265633424,0.0007276608856956933,-0.03024048909677002,-0.026288621604391698,-0.025762536365439473,-0.02559595156684432,-0.027210600466361468,-0.020458669168220246,0.015656097745314942,0.016679747167011306,0.015545545490334203,0.017782185411655153,0.021107944196120873,0.024289902355773215,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.018470079971203812,0.018391873734613588,0.01079722572958122,0.010033775003371334,0.013244389261333688,0.013098362591741953,0.011632682677416312,-0.0015522512754899958,-0.028106659128546027,-0.0261378503004198,-0.025862700639088788,-0.02614869048345702,-0.027580712039268648,0.0048172628541727144,0.017272462973503582,0.017122197954086604,0.015106727025693842,0.014933081403582368,0.019465681092784144,0.026262302756164722,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.021958749435626645,0.016025097272687146,0.012462897060723796,0.014963538316109257,0.015587668519149235,0.01498871348960805,0.01500841123667687,-0.010561015239943159,-0.026348619351396967,-0.025762045040066205,-0.025838857198501305,-0.026299299867536808,-0.030106985818549103,0.014970826067014673,0.016478883141111483,0.017253795792261866,0.015605740158033114,0.014627817693514147,0.0178700514710854,0.026073662953904456,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.0,0.02283601917525869,0.016755373755712923,0.01430925034051208,0.015704549886747427,0.015660623585994526,0.015757236554203205,0.015885213286874304,-0.02770027642720887,-0.025777397373283623,-0.02574898035959599,-0.026053791803432317,-0.0268625580664062,-0.03278804581202041,0.016815824053891877,0.01638341657104543,0.01735042824062153,0.01617679311450967,0.014073411679984441,0.017635565030453056,0.02403792365001799,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.012280363757529862,0.023079236597302048,0.01649918354710062,0.014781026688634341,0.015775297824204816,0.016110117875023113,0.015869585277387875,0.01100747259753678,-0.024976192961783533,-0.02550610561118499,-0.02601096498171574,-0.026201275283306204,-0.028263996310718496,-0.034595659994009376,0.015539940088608139,0.016198958081253895,0.01709287976710569,0.015391073905206047,0.016574974616923727,0.02001969029734062,0.021565423006376518,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.012280524306899316,0.021371480755620644,0.017006091475513508,0.014938238606219966,0.01601570287898244,0.01633639134736672,0.014728344166303236,-0.02656238788793073,-0.02478911348592172,-0.02538058911930058,-0.026104523178307207,-0.026458567747209838,-0.027907883327692277,-0.02574134017642964,0.011561937411987343,0.01499836713300151,0.01641182680678389,0.018111533791501357,0.019559301551369587,0.017306527008519573,0.0169293377091307,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.012280361135167927,0.021449053141433787,0.017391667983806244,0.015109460960812797,0.016232865911858067,0.016266398941880346,0.007593760394797345,-0.024945795444877635,-0.024633588765074464,-0.02536613784069387,-0.026085821273451312,-0.027082758604850755,-0.030317595692449604,-0.000548669689817146,0.009819575987834386,0.013915881504165471,0.018306929399275796,0.019341350969113918,0.016487627073713436,0.015258061492455099,0.016488319497902564,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.012280460203102214,0.018253148689564153,0.018664641679104293,0.016168076887730334,0.016232706306106442,0.015385063114213397,-0.03175056827902308,-0.02505711583510343,-0.024961154235994324,-0.02585498641731635,-0.026655572305209926,-0.027975985985224817,-0.033519799528605614,0.010662901756973908,0.014652292417810388,0.015132600851359559,0.015485827705314627,0.013966667686396423,0.014620289763664024,0.016046514655300517,0.01699011979761207,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.012280460203102214,0.01488545316611946,0.01765016682302788,0.017672779311586756,0.017166092744979107,0.012449832545725237,-0.03208542614123641,-0.027113323842858247,-0.025959138811688546,-0.026425583516487782,-0.027242966724968717,-0.02910792057164881,-0.015733927456806324,0.00877317668036134,0.008532108739200767,0.006846734512358424,0.008222591466935275,0.012547898879740666,0.01520319655959984,0.016477860613796212,0.017358418834415516,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.01228028295054647,0.014056164199329408,0.01394404189782267,0.013660949031155669,0.015207863821488532,0.01189143591280654,-0.02059222235732446,-0.02839887872800343,-0.027832984097089,-0.02996958466498835,-0.0316643097201938,-0.026678963456593367,-0.003717345056136369,0.0023175453920736217,-0.0009913045346208143,0.009006037551286025,0.008957863807742427,0.011545950567890505,0.016150346604341358,0.01667864173524476,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.0,0.012498093531257809,0.001831400173586676,0.0079430362427473,0.008636649465395246,-0.00036543882311349327,-0.017647322379101084,-0.03191103274607727,-0.03187146975140771,-0.034095107074524435,-0.029626597096331093,-0.019773391453685552,6.673520969231698e-07,0.001945147529793346,0.006557935856281985,0.009751177143336653,0.010982536479745944,0.012707939053987833,0.016605741722179514,0.016316861965154274,-0.031094135289260562,-0.031094135289260562,-0.023056243571075115,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.0,0.0,-0.0400339772841835,-0.010179462013215084,-0.005600918809354928,-0.01640844848883346,-0.022643695834402976,-0.02654520185687845,-0.022094493768039982,-0.024259726344712258,-0.024308286383279754,-0.015317348294435951,0.002397376363608592,0.006526642056117805,0.008703392835532219,0.007752946206916799,0.007934203298980367,0.006416182445948752,0.01487318145653725,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.0,-0.03761974834349059,-0.038974117684688135,-0.03542146241011626,-0.033325104093794786,-0.032315740176974285,-0.02130705353906342,-0.0065947590150886165,-0.01048580317709908,-0.014238162544588115,-0.009454444702127704,0.005751878185214908,0.00396919803943824,0.007281227938622004,0.004270191667601827,-0.018985986369063027,-0.03551029269616114,0.013836255204792886,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,-0.031094135289260562,0.0,0.0,-0.02700670665492304,-0.02556301522120759,-0.026402740797749628,-0.03235269519530708,0.013851464515906959,0.01886695710118907,0.014023049646492019,0.013947456535631063,0.017116125128154653,0.01650987252616911,0.016167098335004553,0.015482530753028297]\n","Intercept: -0.031094138765801096\n"]}],"source":["# Index labels, adding metadata to the label column.\n","# Fit on whole dataset to include all labels in index.\n","labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n","# Scale features.\n","featureScaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaledFeatures\").fit(data)\n","\n","# Split the data into training and test sets (30% held out for testing)\n","(trainingData, testData) = data.randomSplit([0.7, 0.3])\n","\n","# Train a FM model.\n","fm = FMClassifier(labelCol=\"indexedLabel\", featuresCol=\"scaledFeatures\", stepSize=0.001)\n","\n","# Create a Pipeline.\n","pipeline = Pipeline(stages=[labelIndexer, featureScaler, fm])\n","\n","# Train model.\n","model = pipeline.fit(trainingData)\n","\n","# Make predictions.\n","predictions = model.transform(testData)\n","\n","# Select example rows to display.\n","predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n","\n","# Select (prediction, true label) and compute test accuracy\n","evaluator = MulticlassClassificationEvaluator(\n","    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","accuracy = evaluator.evaluate(predictions)\n","print(\"Test set accuracy = %g\" % accuracy)\n","\n","fmModel = model.stages[2]\n","print(\"Factors: \" + str(fmModel.factors))  # type: ignore\n","print(\"Linear: \" + str(fmModel.linear))  # type: ignore\n","print(\"Intercept: \" + str(fmModel.intercept))  # type: ignore"]},{"cell_type":"markdown","id":"bd2ccf57","metadata":{"papermill":{"duration":0.022167,"end_time":"2022-11-27T07:12:23.011734","exception":false,"start_time":"2022-11-27T07:12:22.989567","status":"completed"},"tags":[]},"source":["### Naive Bayes Classifier\n","\n","Naive Bayes can be trained very efficiently. With a single pass over the training data, it computes the conditional probability distribution of each feature given each label. For prediction, it applies Bayes’ theorem to compute the conditional probability distribution of each label given an observation.\n","\n","MLlib supports Multinomial naive Bayes, Complement naive Bayes, Bernoulli naive Bayes and Gaussian naive Bayes."]},{"cell_type":"code","execution_count":8,"id":"fac8b389","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:12:23.059281Z","iopub.status.busy":"2022-11-27T07:12:23.058002Z","iopub.status.idle":"2022-11-27T07:12:24.316116Z","shell.execute_reply":"2022-11-27T07:12:24.314052Z"},"papermill":{"duration":1.286518,"end_time":"2022-11-27T07:12:24.32113","exception":false,"start_time":"2022-11-27T07:12:23.034612","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["22/11/27 07:12:23 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n","+-----+--------------------+--------------------+-----------+----------+\n","|label|            features|       rawPrediction|probability|prediction|\n","+-----+--------------------+--------------------+-----------+----------+\n","|  0.0|(692,[95,96,97,12...|[-172664.79564650...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[98,99,100,1...|[-176279.15054306...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[122,123,124...|[-189600.55409526...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[124,125,126...|[-274673.88337431...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[124,125,126...|[-183393.03869049...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[125,126,127...|[-256992.48807619...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[126,127,128...|[-210411.53649773...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[127,128,129...|[-170627.63616681...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[127,128,129...|[-212157.96750469...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[127,128,129...|[-183253.80108550...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[128,129,130...|[-246528.93739632...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[150,151,152...|[-158348.34683571...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[152,153,154...|[-210229.50765957...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[152,153,154...|[-242985.16248889...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[152,153,154...|[-94622.933454005...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[153,154,155...|[-266465.39689814...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[153,154,155...|[-144989.71469229...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[154,155,156...|[-283834.57437738...|  [1.0,0.0]|       0.0|\n","|  0.0|(692,[181,182,183...|[-155256.59399829...|  [1.0,0.0]|       0.0|\n","|  1.0|(692,[100,101,102...|[-147726.11958982...|  [0.0,1.0]|       1.0|\n","+-----+--------------------+--------------------+-----------+----------+\n","only showing top 20 rows\n","\n"]}],"source":["data = spark.read.format(\"libsvm\") \\\n","    .load(\"/kaggle/input/mllib-datasets/sample_libsvm_data.txt\")\n","\n","# Split the data into train and test\n","splits = data.randomSplit([0.6, 0.4], 1234)\n","train = splits[0]\n","test = splits[1]\n","\n","# create the trainer and set its parameters\n","nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n","\n","# train the model\n","model = nb.fit(train)\n","\n","# select example rows to display.\n","predictions = model.transform(test)\n","predictions.show()"]},{"cell_type":"code","execution_count":9,"id":"aab70dd1","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:12:24.387807Z","iopub.status.busy":"2022-11-27T07:12:24.387413Z","iopub.status.idle":"2022-11-27T07:12:24.65213Z","shell.execute_reply":"2022-11-27T07:12:24.650768Z"},"papermill":{"duration":0.298723,"end_time":"2022-11-27T07:12:24.654734","exception":false,"start_time":"2022-11-27T07:12:24.356011","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------+--------------------+\n","|prediction|            features|\n","+----------+--------------------+\n","|       1.0|(692,[100,101,102...|\n","|       1.0|(692,[123,124,125...|\n","|       1.0|(692,[124,125,126...|\n","|       1.0|(692,[124,125,126...|\n","|       1.0|(692,[125,126,127...|\n","|       1.0|(692,[125,126,127...|\n","|       1.0|(692,[126,127,128...|\n","|       1.0|(692,[126,127,128...|\n","|       1.0|(692,[127,128,129...|\n","|       1.0|(692,[127,128,129...|\n","|       1.0|(692,[127,128,154...|\n","|       1.0|(692,[128,129,130...|\n","|       1.0|(692,[128,129,130...|\n","|       1.0|(692,[128,129,130...|\n","|       1.0|(692,[128,129,155...|\n","|       1.0|(692,[129,130,131...|\n","|       1.0|(692,[129,130,131...|\n","|       1.0|(692,[130,131,132...|\n","|       1.0|(692,[152,153,154...|\n","|       1.0|(692,[154,155,156...|\n","+----------+--------------------+\n","only showing top 20 rows\n","\n"]}],"source":["from pyspark.sql.functions import *\n","predictions. \\\n","    select(col(\"prediction\"),col(\"features\")). \\\n","    filter(\"prediction = 1.0\"). \\\n","    show()"]},{"cell_type":"code","execution_count":10,"id":"26ebb130","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:12:24.700399Z","iopub.status.busy":"2022-11-27T07:12:24.699966Z","iopub.status.idle":"2022-11-27T07:12:25.073184Z","shell.execute_reply":"2022-11-27T07:12:25.071869Z"},"papermill":{"duration":0.39974,"end_time":"2022-11-27T07:12:25.076519","exception":false,"start_time":"2022-11-27T07:12:24.676779","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Test set accuracy = 1.0\n"]}],"source":["# compute accuracy on the test set\n","evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n","                                              metricName=\"accuracy\")\n","accuracy = evaluator.evaluate(predictions)\n","print(\"Test set accuracy = \" + str(accuracy))"]},{"cell_type":"markdown","id":"b4a87710","metadata":{"papermill":{"duration":0.030982,"end_time":"2022-11-27T07:12:25.139061","exception":false,"start_time":"2022-11-27T07:12:25.108079","status":"completed"},"tags":[]},"source":["### One-vs-Rest classifier (a.k.a. One-vs-All)\n","\n","OneVsRest is an example of a machine learning reduction for performing multiclass classification given a base classifier that can perform binary classification efficiently. It is also known as “One-vs-All.”\n","\n","OneVsRest is implemented as an Estimator. For the base classifier, it takes instances of Classifier and creates a binary classification problem for each of the k classes. The classifier for class i is trained to predict whether the label is i or not, distinguishing class i from all other classes.\n","\n","Predictions are done by evaluating each binary classifier and the index of the most confident classifier is output as label."]},{"cell_type":"code","execution_count":11,"id":"c64502f3","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:12:25.205764Z","iopub.status.busy":"2022-11-27T07:12:25.20524Z","iopub.status.idle":"2022-11-27T07:12:29.749966Z","shell.execute_reply":"2022-11-27T07:12:29.748632Z"},"papermill":{"duration":4.582109,"end_time":"2022-11-27T07:12:29.754172","exception":false,"start_time":"2022-11-27T07:12:25.172063","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["22/11/27 07:12:25 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n"]}],"source":["from pyspark.ml.classification import OneVsRest\n","\n","# load data file.\n","inputData = spark.read.format(\"libsvm\") \\\n","    .load(\"/kaggle/input/mllib-datasets/sample_multiclass_classification_data.txt\")\n","\n","# generate the train/test split.\n","(train, test) = inputData.randomSplit([0.8, 0.2])\n","\n","# instantiate the base classifier.\n","lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True)\n","\n","# instantiate the One Vs Rest Classifier.\n","ovr = OneVsRest(classifier=lr)\n","\n","# train the multiclass model.\n","ovrModel = ovr.fit(train)\n","\n","# score the model on test data.\n","predictions = ovrModel.transform(test)"]},{"cell_type":"code","execution_count":12,"id":"c54fa237","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:12:29.802227Z","iopub.status.busy":"2022-11-27T07:12:29.801844Z","iopub.status.idle":"2022-11-27T07:12:32.0777Z","shell.execute_reply":"2022-11-27T07:12:32.076046Z"},"papermill":{"duration":2.302276,"end_time":"2022-11-27T07:12:32.080814","exception":false,"start_time":"2022-11-27T07:12:29.778538","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 161:>                                                        (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["Test Error = 0\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["# obtain evaluator.\n","evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n","\n","# compute the classification error on test data.\n","accuracy = evaluator.evaluate(predictions)\n","print(\"Test Error = %g\" % (1.0 - accuracy))"]},{"cell_type":"markdown","id":"cef94ea4","metadata":{"papermill":{"duration":0.021716,"end_time":"2022-11-27T07:12:32.12852","exception":false,"start_time":"2022-11-27T07:12:32.106804","status":"completed"},"tags":[]},"source":["### Linear Support Vector Machine\n","\n","A support vector machine constructs a hyperplane or set of hyperplanes in a high- or infinite-dimensional space, which can be used for classification, regression, or other tasks. \n","Intuitively, a good separation is achieved by the hyperplane that has the largest distance to the nearest training-data points of any class (so-called functional margin), since in general the larger the margin the lower the generalization error of the classifier. \n","\n","LinearSVC in Spark ML supports binary classification with linear SVM. Internally, it optimizes the Hinge Loss using OWLQN optimizer."]},{"cell_type":"code","execution_count":13,"id":"4dabe33a","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:12:32.175103Z","iopub.status.busy":"2022-11-27T07:12:32.173926Z","iopub.status.idle":"2022-11-27T07:12:35.888988Z","shell.execute_reply":"2022-11-27T07:12:35.887746Z"},"papermill":{"duration":3.742041,"end_time":"2022-11-27T07:12:35.892569","exception":false,"start_time":"2022-11-27T07:12:32.150528","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["22/11/27 07:12:32 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n","22/11/27 07:12:32 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n","22/11/27 07:12:32 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"]}],"source":["# Load training data\n","training = spark.read.format(\"libsvm\").load(\"/kaggle/input/mllib-datasets/sample_libsvm_data.txt\")\n","#You need to send the training set as labels and features\n","lsvc = LinearSVC(maxIter=10, regParam=0.1)\n","\n","# Fit the model\n","lsvcModel = lsvc.fit(training)"]},{"cell_type":"code","execution_count":14,"id":"1006b30a","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:12:35.952525Z","iopub.status.busy":"2022-11-27T07:12:35.95143Z","iopub.status.idle":"2022-11-27T07:12:36.123936Z","shell.execute_reply":"2022-11-27T07:12:36.122555Z"},"papermill":{"duration":0.200186,"end_time":"2022-11-27T07:12:36.127124","exception":false,"start_time":"2022-11-27T07:12:35.926938","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+--------------------+--------------------+----------+\n","|label|            features|       rawPrediction|prediction|\n","+-----+--------------------+--------------------+----------+\n","|  0.0|(692,[127,128,129...|[1.46985828303639...|       0.0|\n","|  1.0|(692,[158,159,160...|[-1.3052815074026...|       1.0|\n","+-----+--------------------+--------------------+----------+\n","only showing top 2 rows\n","\n"]}],"source":["lsvcResult = lsvcModel.transform(training)\n","lsvcResult.show(2)"]},{"cell_type":"markdown","id":"b5d842b7","metadata":{"papermill":{"duration":0.032103,"end_time":"2022-11-27T07:12:36.194868","exception":false,"start_time":"2022-11-27T07:12:36.162765","status":"completed"},"tags":[]},"source":["### Multilayer perceptron classifier\n","\n","Multilayer perceptron classifier (MLPC) is a classifier based on the feedforward artificial neural network. MLPC consists of multiple layers of nodes. Each layer is fully connected to the next layer in the network. Nodes in the input layer represent the input data. "]},{"cell_type":"code","execution_count":15,"id":"efbe4994","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:12:36.256852Z","iopub.status.busy":"2022-11-27T07:12:36.255841Z","iopub.status.idle":"2022-11-27T07:12:39.105328Z","shell.execute_reply":"2022-11-27T07:12:39.103073Z"},"papermill":{"duration":2.881433,"end_time":"2022-11-27T07:12:39.109669","exception":false,"start_time":"2022-11-27T07:12:36.228236","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["22/11/27 07:12:36 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n","+----------+--------------------+-----+\n","|prediction|            features|label|\n","+----------+--------------------+-----+\n","|       0.0|(4,[0,1,2,3],[-0....|  0.0|\n","|       0.0|(4,[0,1,2,3],[-0....|  0.0|\n","+----------+--------------------+-----+\n","only showing top 2 rows\n","\n"]}],"source":["# Load training data\n","data = spark.read.format(\"libsvm\")\\\n","    .load(\"/kaggle/input/mllib-datasets/sample_multiclass_classification_data.txt\")\n","\n","# Split the data into train and test\n","splits = data.randomSplit([0.6, 0.4], 1234)\n","train = splits[0]\n","test = splits[1]\n","\n","# specify layers for the neural network:\n","# input layer of size 4 (features), two intermediate of size 5 and 4\n","# and output of size 3 (classes)\n","layers = [4, 5, 4, 3]\n","\n","# create the trainer and set its parameters\n","trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, \n","                                         blockSize=128, seed=1234)\n","\n","# train the model\n","model = trainer.fit(train)\n","\n","# compute accuracy on the test set\n","result = model.transform(test)\n","predictionAndLabels = result.select(\"prediction\",\"features\",\"label\")\n","predictionAndLabels.show(2)"]},{"cell_type":"markdown","id":"3e5dbd30","metadata":{"papermill":{"duration":0.033347,"end_time":"2022-11-27T07:12:39.176832","exception":false,"start_time":"2022-11-27T07:12:39.143485","status":"completed"},"tags":[]},"source":["### Gradient-boosted tree & Random Forest classifier\n","\n","Gradient-boosted trees (GBTs) are a popular classification and regression method using ensembles of decision trees. More information about the spark.ml implementation can be found further in the section on GBTs.\n","\n","Examples\n","\n","The following examples load a dataset in LibSVM format, split it into training and test sets, train on the first dataset, and then evaluate on the held-out test set. We use two feature transformers to prepare the data; these help index categories for the label and categorical features, adding metadata to the DataFrame which the tree-based algorithms can recognize."]},{"cell_type":"code","execution_count":16,"id":"8e5ca35e","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:12:39.240845Z","iopub.status.busy":"2022-11-27T07:12:39.240389Z","iopub.status.idle":"2022-11-27T07:12:44.586378Z","shell.execute_reply":"2022-11-27T07:12:44.585124Z"},"papermill":{"duration":5.380306,"end_time":"2022-11-27T07:12:44.591223","exception":false,"start_time":"2022-11-27T07:12:39.210917","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["22/11/27 07:12:39 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n","+----------+------------+--------------------+\n","|prediction|indexedLabel|            features|\n","+----------+------------+--------------------+\n","|       1.0|         1.0|(692,[100,101,102...|\n","|       1.0|         1.0|(692,[124,125,126...|\n","|       1.0|         1.0|(692,[126,127,128...|\n","|       1.0|         1.0|(692,[126,127,128...|\n","|       1.0|         1.0|(692,[151,152,153...|\n","+----------+------------+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["# Load and parse the data file, converting it to a DataFrame.\n","data = spark.read.format(\"libsvm\").load(\"/kaggle/input/mllib-datasets/sample_libsvm_data.txt\")\n","\n","# Index labels, adding metadata to the label column.\n","# Fit on whole dataset to include all labels in index.\n","labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n","# Automatically identify categorical features, and index them.\n","# Set maxCategories so features with > 4 distinct values are treated as continuous.\n","featureIndexer =\\\n","    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n","\n","# Split the data into training and test sets (30% held out for testing)\n","(trainingData, testData) = data.randomSplit([0.7, 0.3])\n","\n","# Train a GBT model.\n","gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)\n","\n","# Chain indexers and GBT in a Pipeline\n","pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n","\n","# Train model.  This also runs the indexers.\n","model = pipeline.fit(trainingData)\n","\n","# Make predictions.\n","predictions = model.transform(testData)\n","\n","# Select example rows to display.\n","predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n"]},{"cell_type":"code","execution_count":17,"id":"8b913442","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:12:44.646397Z","iopub.status.busy":"2022-11-27T07:12:44.646024Z","iopub.status.idle":"2022-11-27T07:12:47.004602Z","shell.execute_reply":"2022-11-27T07:12:47.003396Z"},"papermill":{"duration":2.387961,"end_time":"2022-11-27T07:12:47.008373","exception":false,"start_time":"2022-11-27T07:12:44.620412","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["22/11/27 07:12:44 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n","+--------------+-----+--------------------+\n","|predictedLabel|label|            features|\n","+--------------+-----+--------------------+\n","|           0.0|  0.0|(692,[98,99,100,1...|\n","|           0.0|  0.0|(692,[122,123,124...|\n","|           0.0|  0.0|(692,[123,124,125...|\n","|           0.0|  0.0|(692,[123,124,125...|\n","|           0.0|  0.0|(692,[124,125,126...|\n","+--------------+-----+--------------------+\n","only showing top 5 rows\n","\n","Test Error = 0\n"]}],"source":["data = spark.read.format(\"libsvm\").load(\"/kaggle/input/mllib-datasets/sample_libsvm_data.txt\")\n","\n","# Index labels, adding metadata to the label column.\n","# Fit on whole dataset to include all labels in index.\n","labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n","\n","# Automatically identify categorical features, and index them.\n","# Set maxCategories so features with > 4 distinct values are treated as continuous.\n","featureIndexer =\\\n","    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n","\n","# Split the data into training and test sets (30% held out for testing)\n","(trainingData, testData) = data.randomSplit([0.7, 0.3])\n","\n","# Train a RandomForest model.\n","rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n","\n","# Convert indexed labels back to original labels.\n","labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n","                               labels=labelIndexer.labels)\n","\n","# Chain indexers and forest in a Pipeline\n","pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n","\n","# Train model.  This also runs the indexers.\n","model = pipeline.fit(trainingData)\n","\n","# Make predictions.\n","predictions = model.transform(testData)\n","\n","# Select example rows to display.\n","predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n","\n","# Select (prediction, true label) and compute test error\n","evaluator = MulticlassClassificationEvaluator(\n","    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","accuracy = evaluator.evaluate(predictions)\n","print(\"Test Error = %g\" % (1.0 - accuracy))"]},{"cell_type":"markdown","id":"f05cf5aa","metadata":{"papermill":{"duration":0.023018,"end_time":"2022-11-27T07:12:47.054861","exception":false,"start_time":"2022-11-27T07:12:47.031843","status":"completed"},"tags":[]},"source":["### Decision tree classifier\n","\n","Decision trees are a popular family of classification and regression methods. More information about the spark.ml implementation can be found further in the section on decision trees.\n","\n","Examples\n","\n","The following examples load a dataset in LibSVM format, split it into training and test sets, train on the first dataset, and then evaluate on the held-out test set. We use two feature transformers to prepare the data; these help index categories for the label and categorical features, adding metadata to the DataFrame which the Decision Tree algorithm can recognize."]},{"cell_type":"code","execution_count":18,"id":"714cfde0","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:12:47.102418Z","iopub.status.busy":"2022-11-27T07:12:47.101989Z","iopub.status.idle":"2022-11-27T07:12:48.625406Z","shell.execute_reply":"2022-11-27T07:12:48.623215Z"},"papermill":{"duration":1.550585,"end_time":"2022-11-27T07:12:48.628413","exception":false,"start_time":"2022-11-27T07:12:47.077828","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["22/11/27 07:12:47 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n","+----------+------------+--------------------+\n","|prediction|indexedLabel|            features|\n","+----------+------------+--------------------+\n","|       1.0|         1.0|(692,[98,99,100,1...|\n","|       1.0|         1.0|(692,[124,125,126...|\n","|       1.0|         1.0|(692,[124,125,126...|\n","|       1.0|         1.0|(692,[124,125,126...|\n","|       0.0|         1.0|(692,[125,126,127...|\n","+----------+------------+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["# Load the data stored in LIBSVM format as a DataFrame.\n","data = spark.read.format(\"libsvm\").load(\"/kaggle/input/mllib-datasets/sample_libsvm_data.txt\")\n","\n","# Index labels, adding metadata to the label column.\n","# Fit on whole dataset to include all labels in index.\n","labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n","# Automatically identify categorical features, and index them.\n","# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n","featureIndexer =\\\n","    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n","\n","# Split the data into training and test sets (30% held out for testing)\n","(trainingData, testData) = data.randomSplit([0.7, 0.3])\n","\n","# Train a DecisionTree model.\n","dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n","\n","# Chain indexers and tree in a Pipeline\n","pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n","\n","# Train model.  This also runs the indexers.\n","model = pipeline.fit(trainingData)\n","\n","# Make predictions.\n","predictions = model.transform(testData)\n","\n","# Select example rows to display.\n","predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)"]},{"cell_type":"markdown","id":"ecf1c656","metadata":{"papermill":{"duration":0.023797,"end_time":"2022-11-27T07:12:48.67626","exception":false,"start_time":"2022-11-27T07:12:48.652463","status":"completed"},"tags":[]},"source":["### Multinomial logistic regression\n","\n","Multiclass classification is supported via multinomial logistic (softmax) regression. In multinomial logistic regression, the algorithm produces K sets of coefficients, or a matrix of dimension K×J where K is the number of outcome classes and J is the number of features. If the algorithm is fit with an intercept term then a length K vector of intercepts is available.\n","\n","Multinomial coefficients are available as coefficientMatrix and intercepts are available as interceptVector."]},{"cell_type":"code","execution_count":19,"id":"177d26d1","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:12:48.725261Z","iopub.status.busy":"2022-11-27T07:12:48.724865Z","iopub.status.idle":"2022-11-27T07:12:49.624528Z","shell.execute_reply":"2022-11-27T07:12:49.622283Z"},"papermill":{"duration":0.92801,"end_time":"2022-11-27T07:12:49.627391","exception":false,"start_time":"2022-11-27T07:12:48.699381","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["22/11/27 07:12:48 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n","Coefficients: \n","3 X 4 CSRMatrix\n","(0,3) 0.305\n","(1,2) -0.7666\n","(1,3) -0.3854\n","Intercept: [0.05192580020728831,-0.12619173083598803,0.07426593062869971]\n"]}],"source":["# Load training data\n","training = spark \\\n","    .read \\\n","    .format(\"libsvm\") \\\n","    .load(\"/kaggle/input/mllib-datasets/sample_multiclass_classification_data.txt\")\n","\n","lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n","\n","# Fit the model\n","lrModel = lr.fit(training)\n","lrResuls = lrModel.transform(training)\n","# Print the coefficients and intercept for multinomial logistic regression\n","print(\"Coefficients: \\n\" + str(lrModel.coefficientMatrix))\n","print(\"Intercept: \" + str(lrModel.interceptVector))\n","\n","trainingSummary = lrModel.summary"]},{"cell_type":"code","execution_count":20,"id":"81361927","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:12:49.683923Z","iopub.status.busy":"2022-11-27T07:12:49.683162Z","iopub.status.idle":"2022-11-27T07:12:49.792711Z","shell.execute_reply":"2022-11-27T07:12:49.790247Z"},"papermill":{"duration":0.140199,"end_time":"2022-11-27T07:12:49.79667","exception":false,"start_time":"2022-11-27T07:12:49.656471","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+--------------------+--------------------+--------------------+----------+\n","|label|            features|       rawPrediction|         probability|prediction|\n","+-----+--------------------+--------------------+--------------------+----------+\n","|  1.0|(4,[0,1,2,3],[-0....|[-0.2022406797198...|[0.20047171690188...|       1.0|\n","|  1.0|(4,[0,1,2,3],[-0....|[-0.2276575412124...|[0.18485728304559...|       1.0|\n","+-----+--------------------+--------------------+--------------------+----------+\n","only showing top 2 rows\n","\n"]}],"source":["lrResuls.show(2)"]},{"cell_type":"code","execution_count":21,"id":"1d5e90a4","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:12:49.84824Z","iopub.status.busy":"2022-11-27T07:12:49.847813Z","iopub.status.idle":"2022-11-27T07:12:49.970804Z","shell.execute_reply":"2022-11-27T07:12:49.969562Z"},"papermill":{"duration":0.153461,"end_time":"2022-11-27T07:12:49.976598","exception":false,"start_time":"2022-11-27T07:12:49.823137","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["objectiveHistory:\n","1.098612288668108\n","1.0767872580801818\n","1.0324898663050683\n","1.0276148685544233\n","1.0292979666409194\n","1.0238563624020458\n","1.0236260835897755\n","1.0235478802964153\n","1.0231925082158748\n","1.0231565244620064\n","1.0229939986213705\n","False positive rate by label:\n","label 0: 0.22\n","label 1: 0.05\n","label 2: 0.0\n","True positive rate by label:\n","label 0: 1.0\n","label 1: 1.0\n","label 2: 0.46\n","Precision by label:\n","label 0: 0.6944444444444444\n","label 1: 0.9090909090909091\n","label 2: 1.0\n","Recall by label:\n","label 0: 1.0\n","label 1: 1.0\n","label 2: 0.46\n","F-measure by label:\n","label 0: 0.819672131147541\n","label 1: 0.9523809523809523\n","label 2: 0.6301369863013699\n"]}],"source":["# Obtain the objective per iteration\n","objectiveHistory = trainingSummary.objectiveHistory\n","print(\"objectiveHistory:\")\n","for objective in objectiveHistory:\n","    print(objective)\n","\n","# for multiclass, we can inspect metrics on a per-label basis\n","print(\"False positive rate by label:\")\n","for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n","    print(\"label %d: %s\" % (i, rate))\n","\n","print(\"True positive rate by label:\")\n","for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n","    print(\"label %d: %s\" % (i, rate))\n","\n","print(\"Precision by label:\")\n","for i, prec in enumerate(trainingSummary.precisionByLabel):\n","    print(\"label %d: %s\" % (i, prec))\n","\n","print(\"Recall by label:\")\n","for i, rec in enumerate(trainingSummary.recallByLabel):\n","    print(\"label %d: %s\" % (i, rec))\n","\n","print(\"F-measure by label:\")\n","for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n","    print(\"label %d: %s\" % (i, f))\n","\n","accuracy = trainingSummary.accuracy\n","falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n","truePositiveRate = trainingSummary.weightedTruePositiveRate\n","fMeasure = trainingSummary.weightedFMeasure()\n","precision = trainingSummary.weightedPrecision\n","recall = trainingSummary.weightedRecall"]},{"cell_type":"code","execution_count":22,"id":"49f9d7fa","metadata":{"execution":{"iopub.execute_input":"2022-11-27T07:12:50.037611Z","iopub.status.busy":"2022-11-27T07:12:50.037192Z","iopub.status.idle":"2022-11-27T07:12:52.333498Z","shell.execute_reply":"2022-11-27T07:12:52.331473Z"},"papermill":{"duration":2.325635,"end_time":"2022-11-27T07:12:52.336813","exception":false,"start_time":"2022-11-27T07:12:50.011178","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["22/11/27 07:12:50 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n","Coefficients: (692,[272,300,323,350,351,378,379,405,406,407,428,433,434,435,455,456,461,462,483,484,489,490,496,511,512,517,539,540,568],[-7.52068987138421e-05,-8.115773146847101e-05,3.814692771846369e-05,0.0003776490540424337,0.00034051483661944103,0.0005514455157343105,0.0004085386116096913,0.000419746733274946,0.0008119171358670028,0.0005027708372668751,-2.3929260406601844e-05,0.000574504802090229,0.0009037546426803721,7.818229700244018e-05,-2.1787551952912764e-05,-3.4021658217896256e-05,0.0004966517360637634,0.0008190557828370367,-8.017982139522704e-05,-2.7431694037836214e-05,0.0004810832226238988,0.00048408017626778765,-8.926472920011488e-06,-0.00034148812330427335,-8.950592574121486e-05,0.00048645469116892167,-8.478698005186209e-05,-0.0004234783215831763,-7.29653577763134e-05])\n","Intercept: -0.5991460286401435\n","Multinomial coefficients: 2 X 692 CSRMatrix\n","(0,272) 0.0001\n","(0,300) 0.0001\n","(0,350) -0.0002\n","(0,351) -0.0001\n","(0,378) -0.0003\n","(0,379) -0.0002\n","(0,405) -0.0002\n","(0,406) -0.0004\n","(0,407) -0.0002\n","(0,433) -0.0003\n","(0,434) -0.0005\n","(0,435) -0.0001\n","(0,456) 0.0\n","(0,461) -0.0002\n","(0,462) -0.0004\n","(0,483) 0.0001\n","..\n","..\n","Multinomial intercepts: [0.2750587585718093,-0.2750587585718093]\n"]}],"source":["# Load training data for Binomial classification\n","training = spark.read.format(\"libsvm\").load(\"/kaggle/input/mllib-datasets/sample_libsvm_data.txt\")\n","\n","lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n","\n","# Fit the model\n","lrModel = lr.fit(training)\n","\n","# Print the coefficients and intercept for logistic regression\n","print(\"Coefficients: \" + str(lrModel.coefficients))\n","print(\"Intercept: \" + str(lrModel.intercept))\n","\n","# We can also use the multinomial family for binary classification\n","mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n","\n","# Fit the model\n","mlrModel = mlr.fit(training)\n","\n","# Print the coefficients and intercepts for logistic regression with multinomial family\n","print(\"Multinomial coefficients: \" + str(mlrModel.coefficientMatrix))\n","print(\"Multinomial intercepts: \" + str(mlrModel.interceptVector))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":121.802441,"end_time":"2022-11-27T07:12:54.993364","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-11-27T07:10:53.190923","version":"2.3.4"}},"nbformat":4,"nbformat_minor":5}