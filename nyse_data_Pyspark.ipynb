{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6899ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c64cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/24 10:19:45 WARN Utils: Your hostname, codeStation resolves to a loopback address: 127.0.1.1; using 192.168.57.83 instead (on interface wlo1)\n",
      "22/11/24 10:19:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/24 10:19:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"NYSE\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c058dc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.57.83:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>NYSE</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=NYSE>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9025eb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nyse_path = \"/run/media/solverbot/repoA/gitFolders/data-engineering-spark/data/nyse\"\n",
    "de_path = \"/run/media/solverbot/repoA/gitFolders/moreDE\"\n",
    "companyList = spark.read.csv(nyse_path+\"/companylist_noheader.csv\",inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5aa90b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-----+-----+-----+-----+------+\n",
      "|company_name|       date| open| high|  low|close|volume|\n",
      "+------------+-----------+-----+-----+-----+-----+------+\n",
      "|           A|01-Jan-2013|40.94|40.94|40.94|40.94|     0|\n",
      "|          AA|01-Jan-2013| 8.68| 8.68| 8.68| 8.68|     0|\n",
      "+------------+-----------+-----+-----+-----+-----+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.unpack_archive(nyse_path+\"/nyse_data.tar.gz\",extract_dir='nyse_year')\n",
    "nyse_yearly = spark.read.csv(de_path+\"/nyse_year\",inferSchema=True). \\\n",
    "        toDF(\"company_name\",\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\")\n",
    "nyse_yearly.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db836c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS nyse_database\")\n",
    "spark.sql(\"USE nyse_database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "320f62a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#reading from the spark_database\n",
    "nyse_yearly = spark.read.parquet(\"spark-warehouse/nyse_database.db/nyse_table_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22eb98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "  SELECT TO_DATE(CAST(UNIX_TIMESTAMP('12/31/2049', 'MM/dd/yyyy') AS TIMESTAMP)) AS newdate\"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61ff956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_yearly.select(\"company_name\",\"date\",\"open\",\"high\",\"low\",\"close\",\n",
    "                \"volume\",substring(col(\"date\"),8,10).alias('year')).createOrReplaceTempView(\"nyse_table_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a5164f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-----+-----+-----+-----+------+----+\n",
      "|company_name|       date| open| high|  low|close|volume|year|\n",
      "+------------+-----------+-----+-----+-----+-----+------+----+\n",
      "|           A|01-Jan-2013|40.94|40.94|40.94|40.94|     0|2013|\n",
      "|          AA|01-Jan-2013| 8.68| 8.68| 8.68| 8.68|     0|2013|\n",
      "|         AAN|01-Jan-2013|28.28|28.28|28.28|28.28|     0|2013|\n",
      "|         AAP|01-Jan-2013|72.35|72.35|72.35|72.35|     0|2013|\n",
      "|         AAT|01-Jan-2013|27.93|27.93|27.93|27.93|     0|2013|\n",
      "+------------+-----------+-----+-----+-----+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM nyse_table_raw LIMIT 5\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cad58a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|current_date()|\n",
      "+--------------+\n",
      "|    2022-11-24|\n",
      "|    2022-11-24|\n",
      "+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyse_yearly.select(current_date()). \\\n",
    "    show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aebbc7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-----------+\n",
      "|namespace|     tableName|isTemporary|\n",
      "+---------+--------------+-----------+\n",
      "|         |nyse_table_raw|       true|\n",
      "+---------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca669e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function lit in module pyspark.sql.functions:\n",
      "\n",
      "lit(col: Any) -> pyspark.sql.column.Column\n",
      "    Creates a :class:`~pyspark.sql.Column` of literal value.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df.select(lit(5).alias('height')).withColumn('spark_user', lit(True)).take(1)\n",
      "    [Row(height=5, spark_user=True)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23a104c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-----+-----+-----+-----+------+\n",
      "|company_name|       date| open| high|  low|close|volume|\n",
      "+------------+-----------+-----+-----+-----+-----+------+\n",
      "|           A|01-Jan-2013|40.94|40.94|40.94|40.94|     0|\n",
      "+------------+-----------+-----+-----+-----+-----+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyse_yearly.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e68153c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+\n",
      "|date_format(DATE '1970-01-31', d)|\n",
      "+---------------------------------+\n",
      "|                               31|\n",
      "+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select date_format(date '1970-01-31', 'd')\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b025218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+\n",
      "|date_format(DATE '1970-01-31', MMM)|\n",
      "+-----------------------------------+\n",
      "|                                Jan|\n",
      "+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select date_format(date '1970-01-31', 'MMM')\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6dbdf3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|date_format(1970-Jan-31, d)|\n",
      "+---------------------------+\n",
      "|                       null|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select date_format('1970-Jan-31', 'd')\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6f4e33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+\n",
      "|year|company_name|\n",
      "+----+------------+\n",
      "|2013|           A|\n",
      "|2013|          AA|\n",
      "|2013|         AAN|\n",
      "|2013|         AAP|\n",
      "|2013|         AAT|\n",
      "+----+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT year, company_name FROM nyse_table_raw LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f14a1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 34:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+\n",
      "|yearlyCount|year|\n",
      "+-----------+----+\n",
      "|     145126|2014|\n",
      "|     567649|2009|\n",
      "|     600688|2010|\n",
      "|     648323|2011|\n",
      "|     711845|2012|\n",
      "|     798061|2013|\n",
      "+-----------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#getting the count of the nyse data for each year\n",
    "spark.sql(\"\"\"SELECT COUNT(company_name) as yearlyCount, year\n",
    "            FROM nyse_table_raw\n",
    "            GROUP BY year\n",
    "            ORDER BY COUNT(company_name)\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "756496c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+\n",
      "|listedCompanies|year|\n",
      "+---------------+----+\n",
      "|           3249|2014|\n",
      "|           2240|2009|\n",
      "|           2407|2010|\n",
      "|           2581|2011|\n",
      "|           2905|2012|\n",
      "|           3215|2013|\n",
      "+---------------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#number of companies listed each year in NYSE\n",
    "spark.sql(\"\"\"SELECT COUNT(DISTINCT company_name) as listedCompanies, year\n",
    "            FROM nyse_table_raw\n",
    "            GROUP BY year\n",
    "            ORDER BY COUNT(company_name)\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0af739fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2240"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the number of companies listed in 2009\n",
    "spark.sql(\"\"\"SELECT DISTINCT company_name, substring(date, 8,10) AS year\n",
    "                FROM nyse_table_raw\n",
    "                WHERE substring(date, 8, 10) = '2009'\n",
    "                ORDER BY company_name DESC\"\"\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a56824",
   "metadata": {},
   "source": [
    "### Found that table can be loaded but hive support is required\n",
    "spark.sql(\"\"\"LOAD DATA LOCAL INPATH '/spark-warehouse/nyse-database.db/nyse_table_raw'\n",
    "    OVERWRITE INTO TABLE nyse_table_raw\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05c0f2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function date_format in module pyspark.sql.functions:\n",
      "\n",
      "date_format(date: 'ColumnOrName', format: str) -> pyspark.sql.column.Column\n",
      "    Converts a date/timestamp/string to a value of string in the format specified by the date\n",
      "    format given by the second argument.\n",
      "    \n",
      "    A pattern could be for instance `dd.MM.yyyy` and could return a string like '18.03.1993'. All\n",
      "    pattern letters of `datetime pattern`_. can be used.\n",
      "    \n",
      "    .. _datetime pattern: https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html\n",
      "    \n",
      "    .. versionadded:: 1.5.0\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Whenever possible, use specialized functions like `year`.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = spark.createDataFrame([('2015-04-08',)], ['dt'])\n",
      "    >>> df.select(date_format('dt', 'MM/dd/yyy').alias('date')).collect()\n",
      "    [Row(date='04/08/2015')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c07b460e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|       date|\n",
      "+-----------+\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "|01-Jan-2013|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyse_yearly.select(\"date\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "208f4238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|extract(month FROM date)|\n",
      "+------------------------+\n",
      "|                    null|\n",
      "|                    null|\n",
      "|                    null|\n",
      "|                    null|\n",
      "|                    null|\n",
      "+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT EXTRACT(month FROM date(date))\n",
    "                FROM nyse_table_raw\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d99476e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa542c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
